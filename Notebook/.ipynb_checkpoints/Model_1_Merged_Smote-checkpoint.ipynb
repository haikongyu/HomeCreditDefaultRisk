{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import class_function as cf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>DAYS_LAST_PHONE_CHANGE</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>FLOORSMAX_AVG</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_EMP_PHONE</th>\n",
       "      <th>REGION_RATING_CLIENT</th>\n",
       "      <th>FLAG_WORK_PHONE</th>\n",
       "      <th>REG_CITY_NOT_WORK_CITY</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>REGION_RATING_CLIENT_W_CITY</th>\n",
       "      <th>FLAG_PHONE</th>\n",
       "      <th>LIVE_CITY_NOT_WORK_CITY</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.705433</td>\n",
       "      <td>0.735788</td>\n",
       "      <td>0.155054</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.852140</td>\n",
       "      <td>0.307542</td>\n",
       "      <td>0.090287</td>\n",
       "      <td>0.256321</td>\n",
       "      <td>0.888839</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.959566</td>\n",
       "      <td>0.807083</td>\n",
       "      <td>0.569889</td>\n",
       "      <td>0.291700</td>\n",
       "      <td>0.951929</td>\n",
       "      <td>0.727773</td>\n",
       "      <td>0.311736</td>\n",
       "      <td>0.045016</td>\n",
       "      <td>0.477114</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.648326</td>\n",
       "      <td>0.810112</td>\n",
       "      <td>0.814130</td>\n",
       "      <td>0.226282</td>\n",
       "      <td>0.827335</td>\n",
       "      <td>0.650190</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.134897</td>\n",
       "      <td>0.348534</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.075999</td>\n",
       "      <td>0.661387</td>\n",
       "      <td>0.856244</td>\n",
       "      <td>0.569889</td>\n",
       "      <td>0.226282</td>\n",
       "      <td>0.601451</td>\n",
       "      <td>0.760751</td>\n",
       "      <td>0.066837</td>\n",
       "      <td>0.107023</td>\n",
       "      <td>0.350846</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.519522</td>\n",
       "      <td>0.742311</td>\n",
       "      <td>0.569889</td>\n",
       "      <td>0.226282</td>\n",
       "      <td>0.825268</td>\n",
       "      <td>0.377472</td>\n",
       "      <td>0.116854</td>\n",
       "      <td>0.392880</td>\n",
       "      <td>0.298591</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AMT_REQ_CREDIT_BUREAU_YEAR  DAYS_ID_PUBLISH  DAYS_LAST_PHONE_CHANGE  \\\n",
       "0                    0.040000         0.705433                0.735788   \n",
       "1                    0.000000         0.959566                0.807083   \n",
       "2                    0.000000         0.648326                0.810112   \n",
       "3                    0.075999         0.661387                0.856244   \n",
       "4                    0.000000         0.519522                0.742311   \n",
       "\n",
       "   EXT_SOURCE_3  FLOORSMAX_AVG  DAYS_REGISTRATION  EXT_SOURCE_2  AMT_CREDIT  \\\n",
       "0      0.155054       0.083300           0.852140      0.307542    0.090287   \n",
       "1      0.569889       0.291700           0.951929      0.727773    0.311736   \n",
       "2      0.814130       0.226282           0.827335      0.650190    0.022472   \n",
       "3      0.569889       0.226282           0.601451      0.760751    0.066837   \n",
       "4      0.569889       0.226282           0.825268      0.377472    0.116854   \n",
       "\n",
       "   REGION_POPULATION_RELATIVE  DAYS_BIRTH  ...  FLAG_EMP_PHONE  \\\n",
       "0                    0.256321    0.888839  ...               0   \n",
       "1                    0.045016    0.477114  ...               0   \n",
       "2                    0.134897    0.348534  ...               0   \n",
       "3                    0.107023    0.350846  ...               0   \n",
       "4                    0.392880    0.298591  ...               0   \n",
       "\n",
       "   REGION_RATING_CLIENT  FLAG_WORK_PHONE  REG_CITY_NOT_WORK_CITY  \\\n",
       "0                     0                0                       0   \n",
       "1                     1                0                       0   \n",
       "2                     0                1                       0   \n",
       "3                     0                0                       0   \n",
       "4                     0                0                       1   \n",
       "\n",
       "   NAME_INCOME_TYPE  NAME_TYPE_SUITE  REGION_RATING_CLIENT_W_CITY  FLAG_PHONE  \\\n",
       "0                 0                0                            0           0   \n",
       "1                 1                1                            1           0   \n",
       "2                 0                0                            0           0   \n",
       "3                 0                0                            0           1   \n",
       "4                 0                0                            0           1   \n",
       "\n",
       "   LIVE_CITY_NOT_WORK_CITY  TARGET  \n",
       "0                        0       1  \n",
       "1                        0       0  \n",
       "2                        0       0  \n",
       "3                        0       0  \n",
       "4                        1       0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_data = pd.read_csv('../Data/result_5.csv')\n",
    "\n",
    "im_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    282686\n",
       "1     24825\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_data.TARGET.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>DAYS_LAST_PHONE_CHANGE</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>FLOORSMAX_AVG</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_EMP_PHONE</th>\n",
       "      <th>REGION_RATING_CLIENT</th>\n",
       "      <th>FLAG_WORK_PHONE</th>\n",
       "      <th>REG_CITY_NOT_WORK_CITY</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>REGION_RATING_CLIENT_W_CITY</th>\n",
       "      <th>FLAG_PHONE</th>\n",
       "      <th>LIVE_CITY_NOT_WORK_CITY</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>211338</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454078</td>\n",
       "      <td>0.481128</td>\n",
       "      <td>0.290713</td>\n",
       "      <td>0.226282</td>\n",
       "      <td>0.657790</td>\n",
       "      <td>0.695754</td>\n",
       "      <td>0.156180</td>\n",
       "      <td>0.491595</td>\n",
       "      <td>0.594194</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86258</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.755732</td>\n",
       "      <td>0.645620</td>\n",
       "      <td>0.809339</td>\n",
       "      <td>0.226282</td>\n",
       "      <td>0.998338</td>\n",
       "      <td>0.881526</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>0.429796</td>\n",
       "      <td>0.391545</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159307</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.398083</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.644839</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0.766253</td>\n",
       "      <td>0.893659</td>\n",
       "      <td>0.310449</td>\n",
       "      <td>0.635991</td>\n",
       "      <td>0.512514</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136799</th>\n",
       "      <td>0.075999</td>\n",
       "      <td>0.286091</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.569889</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.999108</td>\n",
       "      <td>0.329621</td>\n",
       "      <td>0.054603</td>\n",
       "      <td>0.141377</td>\n",
       "      <td>0.615389</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233511</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.488815</td>\n",
       "      <td>0.825955</td>\n",
       "      <td>0.613155</td>\n",
       "      <td>0.226282</td>\n",
       "      <td>0.858828</td>\n",
       "      <td>0.737028</td>\n",
       "      <td>0.284385</td>\n",
       "      <td>0.097136</td>\n",
       "      <td>0.275761</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AMT_REQ_CREDIT_BUREAU_YEAR  DAYS_ID_PUBLISH  DAYS_LAST_PHONE_CHANGE  \\\n",
       "211338                    0.000000         0.454078                0.481128   \n",
       "86258                     0.040000         0.755732                0.645620   \n",
       "159307                    0.080000         0.398083                1.000000   \n",
       "136799                    0.075999         0.286091                0.921016   \n",
       "233511                    0.040000         0.488815                0.825955   \n",
       "\n",
       "        EXT_SOURCE_3  FLOORSMAX_AVG  DAYS_REGISTRATION  EXT_SOURCE_2  \\\n",
       "211338      0.290713       0.226282           0.657790      0.695754   \n",
       "86258       0.809339       0.226282           0.998338      0.881526   \n",
       "159307      0.644839       0.166700           0.766253      0.893659   \n",
       "136799      0.569889       0.083300           0.999108      0.329621   \n",
       "233511      0.613155       0.226282           0.858828      0.737028   \n",
       "\n",
       "        AMT_CREDIT  REGION_POPULATION_RELATIVE  DAYS_BIRTH  ...  \\\n",
       "211338    0.156180                    0.491595    0.594194  ...   \n",
       "86258     0.004449                    0.429796    0.391545  ...   \n",
       "159307    0.310449                    0.635991    0.512514  ...   \n",
       "136799    0.054603                    0.141377    0.615389  ...   \n",
       "233511    0.284385                    0.097136    0.275761  ...   \n",
       "\n",
       "        FLAG_EMP_PHONE  REGION_RATING_CLIENT  FLAG_WORK_PHONE  \\\n",
       "211338               0                     0                0   \n",
       "86258                0                     0                0   \n",
       "159307               0                     1                0   \n",
       "136799               0                     2                0   \n",
       "233511               1                     2                0   \n",
       "\n",
       "        REG_CITY_NOT_WORK_CITY  NAME_INCOME_TYPE  NAME_TYPE_SUITE  \\\n",
       "211338                       0                 0                0   \n",
       "86258                        0                 2                0   \n",
       "159307                       0                 1                0   \n",
       "136799                       0                 2                0   \n",
       "233511                       0                 3                0   \n",
       "\n",
       "        REGION_RATING_CLIENT_W_CITY  FLAG_PHONE  LIVE_CITY_NOT_WORK_CITY  \\\n",
       "211338                            0           1                        0   \n",
       "86258                             0           1                        0   \n",
       "159307                            1           0                        0   \n",
       "136799                            2           1                        0   \n",
       "233511                            2           0                        0   \n",
       "\n",
       "        TARGET  \n",
       "211338       0  \n",
       "86258        0  \n",
       "159307       0  \n",
       "136799       0  \n",
       "233511       0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(im_data.drop(columns=['TARGET']), im_data.TARGET, test_size=0.2)\n",
    "data = pd.concat([X_train, Y_train], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    56453\n",
       "1     5050\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于训练用数据，使用各种处理不平衡数据的方法，得到模型，在测试集上评估模型的好坏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用欠采样方法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data.groupby(\"TARGET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = result.get_group(0)\n",
    "data_1 = result.get_group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226233, 33)\n",
      "(19775, 33)\n"
     ]
    }
   ],
   "source": [
    "print(data_0.shape)\n",
    "print(data_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 19825 * 3\n",
    "data_0_ = data_0.iloc[:19825, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([data_0_, data_1], axis=0)\n",
    "x_train = result.drop(columns=['TARGET'])\n",
    "y_train = result.TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>DAYS_LAST_PHONE_CHANGE</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>FLOORSMAX_AVG</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>...</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>FLAG_EMP_PHONE</th>\n",
       "      <th>REGION_RATING_CLIENT</th>\n",
       "      <th>FLAG_WORK_PHONE</th>\n",
       "      <th>REG_CITY_NOT_WORK_CITY</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>REGION_RATING_CLIENT_W_CITY</th>\n",
       "      <th>FLAG_PHONE</th>\n",
       "      <th>LIVE_CITY_NOT_WORK_CITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>211338</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454078</td>\n",
       "      <td>0.481128</td>\n",
       "      <td>0.290713</td>\n",
       "      <td>0.226282</td>\n",
       "      <td>0.657790</td>\n",
       "      <td>0.695754</td>\n",
       "      <td>0.156180</td>\n",
       "      <td>0.491595</td>\n",
       "      <td>0.594194</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86258</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.755732</td>\n",
       "      <td>0.645620</td>\n",
       "      <td>0.809339</td>\n",
       "      <td>0.226282</td>\n",
       "      <td>0.998338</td>\n",
       "      <td>0.881526</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>0.429796</td>\n",
       "      <td>0.391545</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159307</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.398083</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.644839</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0.766253</td>\n",
       "      <td>0.893659</td>\n",
       "      <td>0.310449</td>\n",
       "      <td>0.635991</td>\n",
       "      <td>0.512514</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136799</th>\n",
       "      <td>0.075999</td>\n",
       "      <td>0.286091</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.569889</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.999108</td>\n",
       "      <td>0.329621</td>\n",
       "      <td>0.054603</td>\n",
       "      <td>0.141377</td>\n",
       "      <td>0.615389</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233511</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.488815</td>\n",
       "      <td>0.825955</td>\n",
       "      <td>0.613155</td>\n",
       "      <td>0.226282</td>\n",
       "      <td>0.858828</td>\n",
       "      <td>0.737028</td>\n",
       "      <td>0.284385</td>\n",
       "      <td>0.097136</td>\n",
       "      <td>0.275761</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AMT_REQ_CREDIT_BUREAU_YEAR  DAYS_ID_PUBLISH  DAYS_LAST_PHONE_CHANGE  \\\n",
       "211338                    0.000000         0.454078                0.481128   \n",
       "86258                     0.040000         0.755732                0.645620   \n",
       "159307                    0.080000         0.398083                1.000000   \n",
       "136799                    0.075999         0.286091                0.921016   \n",
       "233511                    0.040000         0.488815                0.825955   \n",
       "\n",
       "        EXT_SOURCE_3  FLOORSMAX_AVG  DAYS_REGISTRATION  EXT_SOURCE_2  \\\n",
       "211338      0.290713       0.226282           0.657790      0.695754   \n",
       "86258       0.809339       0.226282           0.998338      0.881526   \n",
       "159307      0.644839       0.166700           0.766253      0.893659   \n",
       "136799      0.569889       0.083300           0.999108      0.329621   \n",
       "233511      0.613155       0.226282           0.858828      0.737028   \n",
       "\n",
       "        AMT_CREDIT  REGION_POPULATION_RELATIVE  DAYS_BIRTH  ...  \\\n",
       "211338    0.156180                    0.491595    0.594194  ...   \n",
       "86258     0.004449                    0.429796    0.391545  ...   \n",
       "159307    0.310449                    0.635991    0.512514  ...   \n",
       "136799    0.054603                    0.141377    0.615389  ...   \n",
       "233511    0.284385                    0.097136    0.275761  ...   \n",
       "\n",
       "        NAME_FAMILY_STATUS  FLAG_EMP_PHONE  REGION_RATING_CLIENT  \\\n",
       "211338                   0               0                     0   \n",
       "86258                    1               0                     0   \n",
       "159307                   1               0                     1   \n",
       "136799                   1               0                     2   \n",
       "233511                   1               1                     2   \n",
       "\n",
       "        FLAG_WORK_PHONE  REG_CITY_NOT_WORK_CITY  NAME_INCOME_TYPE  \\\n",
       "211338                0                       0                 0   \n",
       "86258                 0                       0                 2   \n",
       "159307                0                       0                 1   \n",
       "136799                0                       0                 2   \n",
       "233511                0                       0                 3   \n",
       "\n",
       "        NAME_TYPE_SUITE  REGION_RATING_CLIENT_W_CITY  FLAG_PHONE  \\\n",
       "211338                0                            0           1   \n",
       "86258                 0                            0           1   \n",
       "159307                0                            1           0   \n",
       "136799                0                            2           1   \n",
       "233511                0                            2           0   \n",
       "\n",
       "        LIVE_CITY_NOT_WORK_CITY  \n",
       "211338                        0  \n",
       "86258                         0  \n",
       "159307                        0  \n",
       "136799                        0  \n",
       "233511                        0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=10, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=10, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "xg_cla = xgb.XGBClassifier(max_depth=10, n_estimators=100, random_state=0, scale_pos_weight=10)\n",
    "\n",
    "#模型训练\n",
    "xg_cla.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Real +          Real -     \n",
      "   Predict +         4785            45809     \n",
      "   Predict -          265            10644     \n",
      "\n",
      "准确率： 0.25086581142383296\n",
      "召回率： 0.9475247524752475\n",
      "精准率： 0.09457643198798277\n",
      "\n",
      "漏警率： 0.05247524752475252\n",
      "虚警率： 0.9054235680120173\n",
      "F1: 0.17198619797282727\n",
      "fpr: 0.8114537757072254\n"
     ]
    }
   ],
   "source": [
    "import class_function as cf\n",
    "\n",
    "Y_predicted = xg_cla.predict(X_test)\n",
    "fbc = cf.For_binary_classifier(Y_predicted, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "召回率明显提高，但删除的0类包含了重要的信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SMOTE in module imblearn.over_sampling._smote:\n",
      "\n",
      "class SMOTE(SVMSMOTE, BorderlineSMOTE)\n",
      " |  Class to perform over-sampling using SMOTE.\n",
      " |  \n",
      " |  This object is an implementation of SMOTE - Synthetic Minority\n",
      " |  Over-sampling Technique as presented in [1]_.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <smote_adasyn>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  sampling_strategy : float, str, dict or callable, (default='auto')\n",
      " |      Sampling information to resample the data set.\n",
      " |  \n",
      " |      - When ``float``, it corresponds to the desired ratio of the number of\n",
      " |        samples in the majority class over the number of samples in the\n",
      " |        minority class after resampling. Therefore, the ratio is expressed as\n",
      " |        :math:`\\alpha_{os} = N_{M} / N_{rm}` where :math:`N_{rm}` and\n",
      " |        :math:`N_{M}` are the number of samples in the minority class after\n",
      " |        resampling and the number of samples in the majority class,\n",
      " |        respectively.\n",
      " |  \n",
      " |          .. warning::\n",
      " |             ``float`` is only available for **binary** classification. An\n",
      " |             error is raised for multi-class classification.\n",
      " |  \n",
      " |      - When ``str``, specify the class targeted by the resampling. The\n",
      " |        number of samples in the different classes will be equalized.\n",
      " |        Possible choices are:\n",
      " |  \n",
      " |          ``'minority'``: resample only the minority class;\n",
      " |  \n",
      " |          ``'not minority'``: resample all classes but the minority class;\n",
      " |  \n",
      " |          ``'not majority'``: resample all classes but the majority class;\n",
      " |  \n",
      " |          ``'all'``: resample all classes;\n",
      " |  \n",
      " |          ``'auto'``: equivalent to ``'not majority'``.\n",
      " |  \n",
      " |      - When ``dict``, the keys correspond to the targeted classes. The\n",
      " |        values correspond to the desired number of samples for each targeted\n",
      " |        class.\n",
      " |  \n",
      " |      - When callable, function taking ``y`` and returns a ``dict``. The keys\n",
      " |        correspond to the targeted classes. The values correspond to the\n",
      " |        desired number of samples for each class.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      Control the randomization of the algorithm.\n",
      " |  \n",
      " |      - If int, ``random_state`` is the seed used by the random number\n",
      " |        generator;\n",
      " |      - If ``RandomState`` instance, random_state is the random number\n",
      " |        generator;\n",
      " |      - If ``None``, the random number generator is the ``RandomState``\n",
      " |        instance used by ``np.random``.\n",
      " |  \n",
      " |  k_neighbors : int or object, optional (default=5)\n",
      " |      If ``int``, number of nearest neighbours to used to construct synthetic\n",
      " |      samples.  If object, an estimator that inherits from\n",
      " |      :class:`sklearn.neighbors.base.KNeighborsMixin` that will be used to\n",
      " |      find the k_neighbors.\n",
      " |  \n",
      " |  m_neighbors : int or object, optional (default=10)\n",
      " |      If int, number of nearest neighbours to use to determine if a minority\n",
      " |      sample is in danger. Used with ``kind={'borderline1', 'borderline2',\n",
      " |      'svm'}``.  If object, an estimator that inherits\n",
      " |      from :class:`sklearn.neighbors.base.KNeighborsMixin` that will be used\n",
      " |      to find the k_neighbors.\n",
      " |  \n",
      " |      .. deprecated:: 0.4\n",
      " |         ``m_neighbors`` is deprecated in 0.4 and will be removed in 0.6. Use\n",
      " |         :class:`BorderlineSMOTE` or :class:`SVMSMOTE` instead to use the\n",
      " |         intended algorithm.\n",
      " |  \n",
      " |  out_step : float, optional (default=0.5)\n",
      " |      Step size when extrapolating. Used with ``kind='svm'``.\n",
      " |  \n",
      " |      .. deprecated:: 0.4\n",
      " |         ``out_step`` is deprecated in 0.4 and will be removed in 0.6. Use\n",
      " |         :class:`SVMSMOTE` instead to use the intended algorithm.\n",
      " |  \n",
      " |  kind : str, optional (default='regular')\n",
      " |      The type of SMOTE algorithm to use one of the following options:\n",
      " |      ``'regular'``, ``'borderline1'``, ``'borderline2'``, ``'svm'``.\n",
      " |  \n",
      " |      .. deprecated:: 0.4\n",
      " |         ``kind`` is deprecated in 0.4 and will be removed in 0.6. Use\n",
      " |         :class:`BorderlineSMOTE` or :class:`SVMSMOTE` instead to use the\n",
      " |         intended algorithm.\n",
      " |  \n",
      " |  svm_estimator : object, optional (default=SVC())\n",
      " |      If ``kind='svm'``, a parametrized :class:`sklearn.svm.SVC`\n",
      " |      classifier can be passed.\n",
      " |  \n",
      " |      .. deprecated:: 0.4\n",
      " |         ``out_step`` is deprecated in 0.4 and will be removed in 0.6. Use\n",
      " |         :class:`SVMSMOTE` instead to use the intended algorithm.\n",
      " |  \n",
      " |  n_jobs : int, optional (default=1)\n",
      " |      The number of threads to open if possible.\n",
      " |  \n",
      " |  ratio : str, dict, or callable\n",
      " |      .. deprecated:: 0.4\n",
      " |         Use the parameter ``sampling_strategy`` instead. It will be removed\n",
      " |         in 0.6.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  See the original papers: [1]_ for more details.\n",
      " |  \n",
      " |  Supports multi-class resampling. A one-vs.-rest scheme is used as\n",
      " |  originally proposed in [1]_.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  SMOTENC : Over-sample using SMOTE for continuous and categorical features.\n",
      " |  \n",
      " |  BorderlineSMOTE : Over-sample using the borderline-SMOTE variant.\n",
      " |  \n",
      " |  SVMSMOTE : Over-sample using the SVM-SMOTE variant.\n",
      " |  \n",
      " |  ADASYN : Over-sample using ADASYN.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] N. V. Chawla, K. W. Bowyer, L. O.Hall, W. P. Kegelmeyer, \"SMOTE:\n",
      " |     synthetic minority over-sampling technique,\" Journal of artificial\n",
      " |     intelligence research, 321-357, 2002.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  \n",
      " |  >>> from collections import Counter\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> from imblearn.over_sampling import SMOTE # doctest: +NORMALIZE_WHITESPACE\n",
      " |  >>> X, y = make_classification(n_classes=2, class_sep=2,\n",
      " |  ... weights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0,\n",
      " |  ... n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)\n",
      " |  >>> print('Original dataset shape %s' % Counter(y))\n",
      " |  Original dataset shape Counter({1: 900, 0: 100})\n",
      " |  >>> sm = SMOTE(random_state=42)\n",
      " |  >>> X_res, y_res = sm.fit_resample(X, y)\n",
      " |  >>> print('Resampled dataset shape %s' % Counter(y_res))\n",
      " |  Resampled dataset shape Counter({0: 900, 1: 900})\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SMOTE\n",
      " |      SVMSMOTE\n",
      " |      BorderlineSMOTE\n",
      " |      BaseSMOTE\n",
      " |      imblearn.over_sampling.base.BaseOverSampler\n",
      " |      imblearn.base.BaseSampler\n",
      " |      imblearn.base.SamplerMixin\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, sampling_strategy='auto', random_state=None, k_neighbors=5, m_neighbors='deprecated', out_step='deprecated', kind='deprecated', svm_estimator='deprecated', n_jobs=1, ratio=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from imblearn.base.BaseSampler:\n",
      " |  \n",
      " |  ratio_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from imblearn.base.SamplerMixin:\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Check inputs and statistics of the sampler.\n",
      " |      \n",
      " |      You should use ``fit_resample`` in all cases.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Data array.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target array.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Return the instance itself.\n",
      " |  \n",
      " |  fit_resample(self, X, y)\n",
      " |      Resample the dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Matrix containing the data which have to be sampled.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Corresponding label for each sample in X.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_resampled : {array-like, sparse matrix}, shape (n_samples_new, n_features)\n",
      " |          The array containing the resampled data.\n",
      " |      \n",
      " |      y_resampled : array-like, shape (n_samples_new,)\n",
      " |          The corresponding label of `X_resampled`.\n",
      " |  \n",
      " |  fit_sample = fit_resample(self, X, y)\n",
      " |      Resample the dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Matrix containing the data which have to be sampled.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Corresponding label for each sample in X.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_resampled : {array-like, sparse matrix}, shape (n_samples_new, n_features)\n",
      " |          The array containing the resampled data.\n",
      " |      \n",
      " |      y_resampled : array-like, shape (n_samples_new,)\n",
      " |          The corresponding label of `X_resampled`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import imblearn.over_sampling as imbl_os\n",
    "\n",
    "help(imbl_os.SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=0)\n",
    "x_res, y_res = sm.fit_resample(X_train, Y_train)\n",
    "x_res = pd.DataFrame(x_res, columns=X_test.columns)\n",
    "y_res = pd.Series(y_res, name=Y_test.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=10, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=10, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "xg_cla = xgb.XGBClassifier(max_depth=10, n_estimators=100, random_state=0, scale_pos_weight=10)\n",
    "\n",
    "#模型训练\n",
    "xg_cla.fit(x_res,y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.35149503, 0.648505  ],\n",
       "       [0.8782189 , 0.12178113],\n",
       "       [0.11926407, 0.88073593],\n",
       "       ...,\n",
       "       [0.96760565, 0.03239436],\n",
       "       [0.5507685 , 0.44923154],\n",
       "       [0.27937895, 0.72062105]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predicted = xg_cla.predict_proba(X_test)\n",
    "print(y_res.unique())\n",
    "Y_predicted\n",
    "#fbc = cf.For_binary_classifier(Y_predicted, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    226233\n",
       "0    226233\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on XGBClassifier in module xgboost.sklearn object:\n",
      "\n",
      "class XGBClassifier(XGBModel, sklearn.base.ClassifierMixin)\n",
      " |  Implementation of the scikit-learn API for XGBoost classification.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  max_depth : int\n",
      " |      Maximum tree depth for base learners.\n",
      " |  learning_rate : float\n",
      " |      Boosting learning rate (xgb's \"eta\")\n",
      " |  n_estimators : int\n",
      " |      Number of boosted trees to fit.\n",
      " |  silent : boolean\n",
      " |      Whether to print messages while running boosting.\n",
      " |  objective : string or callable\n",
      " |      Specify the learning task and the corresponding learning objective or\n",
      " |      a custom objective function to be used (see note below).\n",
      " |  booster: string\n",
      " |      Specify which booster to use: gbtree, gblinear or dart.\n",
      " |  nthread : int\n",
      " |      Number of parallel threads used to run xgboost.  (Deprecated, please use ``n_jobs``)\n",
      " |  n_jobs : int\n",
      " |      Number of parallel threads used to run xgboost.  (replaces ``nthread``)\n",
      " |  gamma : float\n",
      " |      Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
      " |  min_child_weight : int\n",
      " |      Minimum sum of instance weight(hessian) needed in a child.\n",
      " |  max_delta_step : int\n",
      " |      Maximum delta step we allow each tree's weight estimation to be.\n",
      " |  subsample : float\n",
      " |      Subsample ratio of the training instance.\n",
      " |  colsample_bytree : float\n",
      " |      Subsample ratio of columns when constructing each tree.\n",
      " |  colsample_bylevel : float\n",
      " |      Subsample ratio of columns for each split, in each level.\n",
      " |  reg_alpha : float (xgb's alpha)\n",
      " |      L1 regularization term on weights\n",
      " |  reg_lambda : float (xgb's lambda)\n",
      " |      L2 regularization term on weights\n",
      " |  scale_pos_weight : float\n",
      " |      Balancing of positive and negative weights.\n",
      " |  base_score:\n",
      " |      The initial prediction score of all instances, global bias.\n",
      " |  seed : int\n",
      " |      Random number seed.  (Deprecated, please use random_state)\n",
      " |  random_state : int\n",
      " |      Random number seed.  (replaces seed)\n",
      " |  missing : float, optional\n",
      " |      Value in the data which needs to be present as a missing value. If\n",
      " |      None, defaults to np.nan.\n",
      " |  importance_type: string, default \"gain\"\n",
      " |      The feature importance type for the feature_importances_ property: either \"gain\",\n",
      " |      \"weight\", \"cover\", \"total_gain\" or \"total_cover\".\n",
      " |  \\*\\*kwargs : dict, optional\n",
      " |      Keyword arguments for XGBoost Booster object.  Full documentation of parameters can\n",
      " |      be found here: https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst.\n",
      " |      Attempting to set a parameter via the constructor args and \\*\\*kwargs dict simultaneously\n",
      " |      will result in a TypeError.\n",
      " |  \n",
      " |      .. note:: \\*\\*kwargs unsupported by scikit-learn\n",
      " |  \n",
      " |          \\*\\*kwargs is unsupported by scikit-learn.  We do not guarantee that parameters\n",
      " |          passed via this argument will interact properly with scikit-learn.\n",
      " |  \n",
      " |  Note\n",
      " |  ----\n",
      " |  A custom objective function can be provided for the ``objective``\n",
      " |  parameter. In this case, it should have the signature\n",
      " |  ``objective(y_true, y_pred) -> grad, hess``:\n",
      " |  \n",
      " |  y_true: array_like of shape [n_samples]\n",
      " |      The target values\n",
      " |  y_pred: array_like of shape [n_samples]\n",
      " |      The predicted values\n",
      " |  \n",
      " |  grad: array_like of shape [n_samples]\n",
      " |      The value of the gradient for each sample point.\n",
      " |  hess: array_like of shape [n_samples]\n",
      " |      The value of the second derivative for each sample point\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      XGBClassifier\n",
      " |      XGBModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, max_depth=3, learning_rate=0.1, n_estimators=100, silent=True, objective='binary:logistic', booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  evals_result(self)\n",
      " |      Return the evaluation results.\n",
      " |      \n",
      " |      If **eval_set** is passed to the `fit` function, you can call\n",
      " |      ``evals_result()`` to get evaluation results for all passed **eval_sets**.\n",
      " |      When **eval_metric** is also passed to the `fit` function, the\n",
      " |      **evals_result** will contain the **eval_metrics** passed to the `fit` function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      evals_result : dictionary\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          param_dist = {'objective':'binary:logistic', 'n_estimators':2}\n",
      " |      \n",
      " |          clf = xgb.XGBClassifier(**param_dist)\n",
      " |      \n",
      " |          clf.fit(X_train, y_train,\n",
      " |                  eval_set=[(X_train, y_train), (X_test, y_test)],\n",
      " |                  eval_metric='logloss',\n",
      " |                  verbose=True)\n",
      " |      \n",
      " |          evals_result = clf.evals_result()\n",
      " |      \n",
      " |      The variable **evals_result** will contain\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          {'validation_0': {'logloss': ['0.604835', '0.531479']},\n",
      " |          'validation_1': {'logloss': ['0.41965', '0.17686']}}\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True, xgb_model=None, sample_weight_eval_set=None, callbacks=None)\n",
      " |      Fit gradient boosting classifier\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like\n",
      " |          Feature matrix\n",
      " |      y : array_like\n",
      " |          Labels\n",
      " |      sample_weight : array_like\n",
      " |          Weight for each instance\n",
      " |      eval_set : list, optional\n",
      " |          A list of (X, y) pairs to use as a validation set for\n",
      " |          early-stopping\n",
      " |      sample_weight_eval_set : list, optional\n",
      " |          A list of the form [L_1, L_2, ..., L_n], where each L_i is a list of\n",
      " |          instance weights on the i-th validation set.\n",
      " |      eval_metric : str, callable, optional\n",
      " |          If a str, should be a built-in evaluation metric to use. See\n",
      " |          doc/parameter.rst. If callable, a custom evaluation metric. The call\n",
      " |          signature is func(y_predicted, y_true) where y_true will be a\n",
      " |          DMatrix object such that you may need to call the get_label\n",
      " |          method. It must return a str, value pair where the str is a name\n",
      " |          for the evaluation and value is the value of the evaluation\n",
      " |          function. This objective is always minimized.\n",
      " |      early_stopping_rounds : int, optional\n",
      " |          Activates early stopping. Validation error needs to decrease at\n",
      " |          least every <early_stopping_rounds> round(s) to continue training.\n",
      " |          Requires at least one item in evals. If there's more than one,\n",
      " |          will use the last. If early stopping occurs, the model will have\n",
      " |          three additional fields: bst.best_score, bst.best_iteration and\n",
      " |          bst.best_ntree_limit (bst.best_ntree_limit is the ntree_limit parameter\n",
      " |          default value in predict method if not any other value is specified).\n",
      " |          (Use bst.best_ntree_limit to get the correct value if num_parallel_tree\n",
      " |          and/or num_class appears in the parameters)\n",
      " |      verbose : bool\n",
      " |          If `verbose` and an evaluation set is used, writes the evaluation\n",
      " |          metric measured on the validation set to stderr.\n",
      " |      xgb_model : str\n",
      " |          file name of stored xgb model or 'Booster' instance Xgb model to be\n",
      " |          loaded before training (allows training continuation).\n",
      " |      callbacks : list of callback functions\n",
      " |          List of callback functions that are applied at end of each iteration.\n",
      " |          It is possible to use predefined callbacks by using :ref:`callback_api`.\n",
      " |          Example:\n",
      " |      \n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              [xgb.callback.reset_learning_rate(custom_rates)]\n",
      " |  \n",
      " |  predict(self, data, output_margin=False, ntree_limit=None, validate_features=True)\n",
      " |      Predict with `data`.\n",
      " |      \n",
      " |      .. note:: This function is not thread safe.\n",
      " |      \n",
      " |        For each booster object, predict can only be called from one thread.\n",
      " |        If you want to run prediction using multiple thread, call ``xgb.copy()`` to make copies\n",
      " |        of model object and then call ``predict()``.\n",
      " |      \n",
      " |      .. note:: Using ``predict()`` with DART booster\n",
      " |      \n",
      " |        If the booster object is DART type, ``predict()`` will perform dropouts, i.e. only\n",
      " |        some of the trees will be evaluated. This will produce incorrect results if ``data`` is\n",
      " |        not the training data. To obtain correct results on test sets, set ``ntree_limit`` to\n",
      " |        a nonzero value, e.g.\n",
      " |      \n",
      " |        .. code-block:: python\n",
      " |      \n",
      " |          preds = bst.predict(dtest, ntree_limit=num_round)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DMatrix\n",
      " |          The dmatrix storing the input.\n",
      " |      output_margin : bool\n",
      " |          Whether to output the raw untransformed margin value.\n",
      " |      ntree_limit : int\n",
      " |          Limit number of trees in the prediction; defaults to best_ntree_limit if defined\n",
      " |          (i.e. it has been trained with early stopping), otherwise 0 (use all trees).\n",
      " |      validate_features : bool\n",
      " |          When this is True, validate that the Booster's and data's feature_names are identical.\n",
      " |          Otherwise, it is assumed that the feature_names are the same.\n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction : numpy array\n",
      " |  \n",
      " |  predict_proba(self, data, ntree_limit=None, validate_features=True)\n",
      " |      Predict the probability of each `data` example being of a given class.\n",
      " |      \n",
      " |      .. note:: This function is not thread safe\n",
      " |      \n",
      " |          For each booster object, predict can only be called from one thread.\n",
      " |          If you want to run prediction using multiple thread, call ``xgb.copy()`` to make copies\n",
      " |          of model object and then call predict\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DMatrix\n",
      " |          The dmatrix storing the input.\n",
      " |      ntree_limit : int\n",
      " |          Limit number of trees in the prediction; defaults to best_ntree_limit if defined\n",
      " |          (i.e. it has been trained with early stopping), otherwise 0 (use all trees).\n",
      " |      validate_features : bool\n",
      " |          When this is True, validate that the Booster's and data's feature_names are identical.\n",
      " |          Otherwise, it is assumed that the feature_names are the same.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction : numpy array\n",
      " |          a numpy array with the probability of each data example being of a given class.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from XGBModel:\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  apply(self, X, ntree_limit=0)\n",
      " |      Return the predicted leaf every tree for each sample.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like, shape=[n_samples, n_features]\n",
      " |          Input features matrix.\n",
      " |      \n",
      " |      ntree_limit : int\n",
      " |          Limit number of trees in the prediction; defaults to 0 (use all trees).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array_like, shape=[n_samples, n_trees]\n",
      " |          For each datapoint x in X and for each tree, return the index of the\n",
      " |          leaf x ends up in. Leaves are numbered within\n",
      " |          ``[0; 2**(self.max_depth+1))``, possibly with gaps in the numbering.\n",
      " |  \n",
      " |  get_booster(self)\n",
      " |      Get the underlying xgboost Booster of this model.\n",
      " |      \n",
      " |      This will raise an exception when fit was not called\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      booster : a xgboost booster of underlying model\n",
      " |  \n",
      " |  get_params(self, deep=False)\n",
      " |      Get parameters.\n",
      " |  \n",
      " |  get_xgb_params(self)\n",
      " |      Get xgboost type parameters.\n",
      " |  \n",
      " |  load_model(self, fname)\n",
      " |      Load the model from a file.\n",
      " |      \n",
      " |      The model is loaded from an XGBoost internal binary format which is\n",
      " |      universal among the various XGBoost interfaces. Auxiliary attributes of\n",
      " |      the Python Booster object (such as feature names) will not be loaded.\n",
      " |      Label encodings (text labels to numeric labels) will be also lost.\n",
      " |      **If you are using only the Python interface, we recommend pickling the\n",
      " |      model object for best results.**\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : string or a memory buffer\n",
      " |          Input file name or memory buffer(see also save_raw)\n",
      " |  \n",
      " |  save_model(self, fname)\n",
      " |      Save the model to a file.\n",
      " |      \n",
      " |      The model is saved in an XGBoost internal binary format which is\n",
      " |      universal among the various XGBoost interfaces. Auxiliary attributes of\n",
      " |      the Python Booster object (such as feature names) will not be loaded.\n",
      " |      Label encodings (text labels to numeric labels) will be also lost.\n",
      " |      **If you are using only the Python interface, we recommend pickling the\n",
      " |      model object for best results.**\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : string\n",
      " |          Output file name\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      Modification of the sklearn method to allow unknown kwargs. This allows using\n",
      " |      the full range of xgboost parameters that are not defined as member variables\n",
      " |      in sklearn grid search.\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from XGBModel:\n",
      " |  \n",
      " |  coef_\n",
      " |      Coefficients property\n",
      " |      \n",
      " |      .. note:: Coefficients are defined only for linear learners\n",
      " |      \n",
      " |          Coefficients are only defined when the linear model is chosen as base\n",
      " |          learner (`booster=gblinear`). It is not defined for other base learner types, such\n",
      " |          as tree learners (`booster=gbtree`).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      coef_ : array of shape ``[n_features]`` or ``[n_classes, n_features]``\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Feature importances property\n",
      " |      \n",
      " |      .. note:: Feature importance is defined only for tree boosters\n",
      " |      \n",
      " |          Feature importance is only defined when the decision tree model is chosen as base\n",
      " |          learner (`booster=gbtree`). It is not defined for other base learner types, such\n",
      " |          as linear learners (`booster=gblinear`).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : array of shape ``[n_features]``\n",
      " |  \n",
      " |  intercept_\n",
      " |      Intercept (bias) property\n",
      " |      \n",
      " |      .. note:: Intercept is defined only for linear learners\n",
      " |      \n",
      " |          Intercept (bias) is only defined when the linear model is chosen as base\n",
      " |          learner (`booster=gblinear`). It is not defined for other base learner types, such\n",
      " |          as tree learners (`booster=gbtree`).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      intercept_ : array of shape ``(1,)`` or ``[n_classes]``\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(xg_cla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
